{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository root: /Users/hamidaho/new_cursor\n",
            "JSONL file: /Users/hamidaho/new_cursor/research/data/companion_traces.jsonl\n",
            "Queries file: /Users/hamidaho/new_cursor/research/data/procedural_search_queries.json\n",
            "Results directory: /Users/hamidaho/new_cursor/research/results\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading traces...\n",
            "Loaded 160 traces (sessions)\n",
            "Total events: 5537\n",
            "\n",
            "Loading queries...\n",
            "Loaded 37 queries\n",
            "\n",
            "Sample query:\n",
            "  ID: proc_1\n",
            "  Text: Find workflows where developers debug an error then write a test\n",
            "  Type: procedural\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building event index...\n",
            "Indexed 5537 events from 160 traces\n",
            "\n",
            "Building rung indices for: raw, tokens, semantic_edits, functions, motifs\n",
            "  Building raw index...\n",
            "    ✓ Indexed 5537 events\n",
            "  Building tokens index...\n",
            "    ✓ Indexed 5537 events\n",
            "  Building semantic_edits index...\n",
            "    ✓ Indexed 5537 events\n",
            "  Building functions index...\n",
            "    ✓ Indexed 5537 events\n",
            "  Building motifs index...\n",
            "    ✓ Indexed 5537 events\n",
            "\n",
            "Event index ready!\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing search engines...\n",
            "✓ Rung search engine ready\n",
            "✓ Using free Hugging Face model: meta-llama/Llama-3.2-3B-Instruct (via InferenceClient)\n",
            "✓ LLM-as-judge ready\n",
            "✓ Using free Hugging Face model: meta-llama/Llama-3.2-3B-Instruct (via InferenceClient)\n",
            "✓ Comparison framework ready\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running comparisons for 37 queries...\n",
            "Retrieving top 20 results per method\n",
            "\n",
            "[1/37] Query: proc_1\n",
            "  Text: Find workflows where developers debug an error then write a test...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[2/37] Query: proc_2\n",
            "  Text: Show me patterns where feature creation is followed by documentation...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[3/37] Query: proc_3\n",
            "  Text: Workflows where code refactoring is followed by test updates...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    functions: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[4/37] Query: proc_4\n",
            "  Text: Find sequences where developers navigate to a file, read code, then make changes...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[5/37] Query: proc_5\n",
            "  Text: Show me debugging patterns that involve multiple file switches...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[6/37] Query: proc_6\n",
            "  Text: Feature development workflows with iterative testing cycles...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[7/37] Query: func_7\n",
            "  Text: Find code that implements authentication with error handling...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[8/37] Query: func_8\n",
            "  Text: Show me patterns where create functions are followed by test functions...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    motifs: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[9/37] Query: func_9\n",
            "  Text: Find functions that were refactored to reduce complexity...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[10/37] Query: func_10\n",
            "  Text: Debugging workflows that involve adding logging functions...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    motifs: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[11/37] Query: func_11\n",
            "  Text: Code patterns with helper functions followed by main implementation...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[12/37] Query: func_12\n",
            "  Text: Find test functions that were added after feature implementation...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    motifs: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[13/37] Query: struct_13\n",
            "  Text: Code with high complexity that was refactored...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    tokens: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    tokens vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[14/37] Query: struct_14\n",
            "  Text: Find patterns with nested conditionals that were simplified...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    tokens: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    tokens vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[15/37] Query: struct_15\n",
            "  Text: Code structures with repeated patterns that were extracted...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    tokens: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    motifs: 20 results\n",
            "    tokens vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[16/37] Query: struct_16\n",
            "  Text: Show me edit patterns with consistent indentation and formatting...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    tokens: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    tokens vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[17/37] Query: struct_17\n",
            "  Text: Find code with class definitions followed by method implementations...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    tokens: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    tokens vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[18/37] Query: module_18\n",
            "  Text: Files that are typically edited together in authentication workflows...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[19/37] Query: module_19\n",
            "  Text: Find file switching patterns during debugging sessions...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[20/37] Query: module_20\n",
            "  Text: Show me files that are frequently co-edited in refactoring workflows...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[21/37] Query: module_21\n",
            "  Text: Dependency patterns where utility files are edited before main files...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[22/37] Query: module_22\n",
            "  Text: Find workflows with test files edited alongside implementation files...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[23/37] Query: module_23\n",
            "  Text: File navigation patterns in documentation workflows...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[24/37] Query: intent_24\n",
            "  Text: Show me all debugging workflows...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "\n",
            "[25/37] Query: intent_25\n",
            "  Text: Feature development patterns...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "\n",
            "[26/37] Query: intent_26\n",
            "  Text: Find all refactoring workflows...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "\n",
            "[27/37] Query: intent_27\n",
            "  Text: Show me testing workflows...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "\n",
            "[28/37] Query: intent_28\n",
            "  Text: Documentation creation patterns...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "\n",
            "[29/37] Query: intent_29\n",
            "  Text: Code explanation and understanding workflows...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "\n",
            "[30/37] Query: hybrid_30\n",
            "  Text: Debugging workflows that involve file switching with iterative patterns...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    motifs: 20 results\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[31/37] Query: hybrid_31\n",
            "  Text: Feature development with function creation, testing, and documentation...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    motifs: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[32/37] Query: hybrid_32\n",
            "  Text: Refactoring workflows with structural changes and test updates...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    tokens: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    functions: 20 results\n",
            "    motifs: 20 results\n",
            "    tokens vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[33/37] Query: hybrid_33\n",
            "  Text: Complex debugging with code reading, file navigation, and iterative fixes...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    semantic_edits: 20 results\n",
            "    motifs: 20 results\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[34/37] Query: context_34\n",
            "  Text: Workflows similar to API endpoint development...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    motifs: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[35/37] Query: context_35\n",
            "  Text: Find workflows similar to authentication system implementation...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    motifs: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[36/37] Query: context_36\n",
            "  Text: Show me workflows similar to database migration patterns...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    semantic_edits: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    semantic_edits vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "[37/37] Query: context_37\n",
            "  Text: Find patterns similar to UI component development workflows...\n",
            "  Warning: InferenceClient failed, trying direct API: 'ProxyClientChat' object has no attribute 'completion'\n",
            "Error in LLM search: Invalid URL 'None': No scheme supplied. Perhaps you meant https://None?\n",
            "  Results:\n",
            "    llm_judge: 0 results\n",
            "    functions: 20 results\n",
            "    motifs: 20 results\n",
            "    functions vs LLM: 0 overlap, Jaccard=0.00\n",
            "    motifs vs LLM: 0 overlap, Jaccard=0.00\n",
            "\n",
            "Completed 37 query comparisons\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results saved to: /Users/hamidaho/new_cursor/research/results/event_retrieval_comparison.json\n",
            "Total queries processed: 37\n",
            "\n",
            "Summary Statistics:\n",
            "Methods used:\n",
            "  functions: 14 queries\n",
            "  llm_judge: 37 queries\n",
            "  motifs: 22 queries\n",
            "  semantic_edits: 14 queries\n",
            "  tokens: 6 queries\n"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
