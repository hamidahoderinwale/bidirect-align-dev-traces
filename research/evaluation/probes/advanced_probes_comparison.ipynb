{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Probes Comparison\n",
    "\n",
    "This notebook extends the baseline probes (`probes_baseline.ipynb`) with advanced machine learning models and interpretability features.\n",
    "\n",
    "## Methods Included (ordered by efficiency):\n",
    "1. **TF-IDF + Logistic Regression** (Baseline) - Fastest, most interpretable\n",
    "2. **Pre-trained Embeddings + Logistic Regression** - Better semantic understanding\n",
    "3. **Fine-tuned Embeddings + Logistic Regression** (Optional) - Task-specific embeddings\n",
    "4. **Random Forest** - Non-linear patterns, interpretable trees\n",
    "5. **Gradient Boosting** - Strong performance, feature importance\n",
    "6. **Lightweight MLP** - Neural network baseline\n",
    "\n",
    "## Outputs:\n",
    "- All results saved to `research/results/advanced_probes_comparison.jsonl` (JSONL format)\n",
    "- Tree visualizations saved to `research/results/random_forest_trees.png`\n",
    "- Feature importance comparison saved to `research/results/feature_importance_comparison.png`\n",
    "- Method comparison summary saved to `research/results/method_comparison_summary.png`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository root: /Users/hamidaho/new_cursor\n",
      "Trace export: /Users/hamidaho/new_cursor/research/data/companion_traces.jsonl\n",
      "Results directory: /Users/hamidaho/new_cursor/research/results\n"
     ]
    }
   ],
   "source": [
    "# Imports and Setup\n",
    "from __future__ import annotations\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Optional\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import altair as alt\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Path setup - MUST BE BEFORE ANY IMPORTS THAT USE REPO_ROOT\n",
    "REPO_ROOT = Path.cwd()\n",
    "while not (REPO_ROOT / 'cursor-telemetry').exists() and not (REPO_ROOT / 'research').exists():\n",
    "    if REPO_ROOT == REPO_ROOT.parent:\n",
    "        break\n",
    "    REPO_ROOT = REPO_ROOT.parent\n",
    "\n",
    "# Add visualization utilities to path (notebook context)\n",
    "sys.path.insert(0, str(REPO_ROOT / \"research\" / \"scripts\"))\n",
    "from visualization import (\n",
    "    plot_bar, plot_scatter, plot_line, plot_heatmap, plot_pareto_frontier,\n",
    "    save_chart, RUNG_COLORS, RUNG_LABELS, COLOR_PALETTE\n",
    ")\n",
    "\n",
    "alt.renderers.enable('default')\n",
    "alt.data_transformers.enable('default')\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import export_text, export_graphviz\n",
    "\n",
    "# Check for sentence-transformers\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    HAS_SENTENCE_TRANSFORMERS = True\n",
    "except ImportError:\n",
    "    HAS_SENTENCE_TRANSFORMERS = False\n",
    "    print(\"âš  sentence-transformers not available. Install with: pip install sentence-transformers\")\n",
    "\n",
    "    # Add research directory to path for imports\n",
    "    RESEARCH_DIR = REPO_ROOT / 'research'\n",
    "    RUNG_EXTRACTORS_DIR = RESEARCH_DIR / 'rung_extractors'\n",
    "    if str(RUNG_EXTRACTORS_DIR) not in sys.path:\n",
    "        sys.path.insert(0, str(RUNG_EXTRACTORS_DIR))\n",
    "    if str(RESEARCH_DIR) not in sys.path:\n",
    "        sys.path.insert(0, str(RESEARCH_DIR))\n",
    "    \n",
    "    from rung_extractors import (\n",
    "        tokens_repr_str,\n",
    "        semantic_edits_repr_str,\n",
    "        functions_repr_str,\n",
    "        motifs_repr_str,\n",
    "        raw_repr_str,\n",
    "    )\n",
    "\n",
    "# Data paths\n",
    "TRACE_EXPORT = REPO_ROOT / 'research/data/companion_traces.jsonl'\n",
    "RESULTS_DIR = REPO_ROOT / 'research/results'\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Repository root: {REPO_ROOT}\")\n",
    "print(f\"Trace export: {TRACE_EXPORT}\")\n",
    "print(f\"Results directory: {RESULTS_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 160 traces\n",
      "Building features (this may take a while)...\n",
      "Using 10 parallel workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-1:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-2:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-8:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-11:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-12:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-13:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-14:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-15:\n",
      "Traceback (most recent call last):\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-16:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-17:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-18:\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-23:\n",
      "Traceback (most recent call last):\n",
      "Process SpawnPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-25:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-26:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-27:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-28:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-29:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-30:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-31:\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-32:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-33:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-34:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-35:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-36:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Process SpawnPoolWorker-37:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-38:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-39:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Process SpawnPoolWorker-40:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 313, in _bootstrap\n",
      "    self.run()\n",
      "    ~~~~~~~~^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/pool.py\", line 114, in worker\n",
      "    task = get()\n",
      "  File \"/opt/homebrew/Cellar/python@3.13/3.13.7/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py\", line 387, in get\n",
      "    return _ForkingPickler.loads(res)\n",
      "           ~~~~~~~~~~~~~~~~~~~~~^^^^^\n",
      "AttributeError: Can't get attribute 'process_single_trace' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# Load traces and build features\n",
    "if not TRACE_EXPORT.exists():\n",
    "    raise FileNotFoundError(f\"Trace export not found at {TRACE_EXPORT}. Run export script first.\")\n",
    "\n",
    "with TRACE_EXPORT.open('r', encoding='utf-8') as fh:\n",
    "    traces = [json.loads(line) for line in fh]\n",
    "\n",
    "print(f\"Loaded {len(traces)} traces\")\n",
    "\n",
    "# Rung extraction functions\n",
    "def tokens_repr(trace):\n",
    "    return tokens_repr_str(trace)\n",
    "\n",
    "def edits_repr(trace):\n",
    "    return semantic_edits_repr_str(trace)\n",
    "\n",
    "def functions_repr(trace):\n",
    "    return functions_repr_str(trace)\n",
    "\n",
    "def motifs_repr(trace):\n",
    "    return motifs_repr_str(trace)\n",
    "\n",
    "def raw_repr(trace):\n",
    "    return raw_repr_str(trace)\n",
    "\n",
    "RUNG_FUNCS = {\n",
    "    'tokens': tokens_repr,\n",
    "    'semantic_edits': edits_repr,\n",
    "    'functions': functions_repr,\n",
    "    'motifs': motifs_repr,\n",
    "    'raw': raw_repr,\n",
    "}\n",
    "\n",
    "# Feature extraction functions (using companion data)\n",
    "def count_code_changes(trace):\n",
    "    \"\"\"Count code/file change events in trace.\"\"\"\n",
    "    # Count entries (code changes) from companion data\n",
    "    count = len(trace.get('entries', []))\n",
    "    # Also count events\n",
    "    code_change_types = ['code_change', 'file_change', 'file_create', 'file_delete', 'file_rename', 'entry_created']\n",
    "    for event in trace.get('events', []):\n",
    "        event_type = (event.get('type') or '').lower()\n",
    "        if any(change_type in event_type for change_type in code_change_types):\n",
    "            count += 1\n",
    "        details = event.get('details', {})\n",
    "        if isinstance(details, dict):\n",
    "            if details.get('after_content') or details.get('before_content') or details.get('code'):\n",
    "                count += 1\n",
    "    return count\n",
    "\n",
    "def count_unique_files(trace):\n",
    "    \"\"\"Count number of unique files modified in trace.\"\"\"\n",
    "    files = set()\n",
    "    # Check entries (code changes) from companion data\n",
    "    for entry in trace.get('entries', []):\n",
    "        file_path = entry.get('file_path')\n",
    "        if file_path:\n",
    "            files.add(str(file_path))\n",
    "    # Also check events\n",
    "    for event in trace.get('events', []):\n",
    "        details = event.get('details', {})\n",
    "        if isinstance(details, dict):\n",
    "            file_path = details.get('file_path') or details.get('path')\n",
    "            if file_path:\n",
    "                files.add(str(file_path))\n",
    "    return len(files)\n",
    "\n",
    "def has_terminal_activity(trace):\n",
    "    \"\"\"Check if trace contains terminal commands.\"\"\"\n",
    "    # Check terminal_commands from companion data\n",
    "    if trace.get('terminal_commands') and len(trace.get('terminal_commands', [])) > 0:\n",
    "        return 1\n",
    "    # Also check events\n",
    "    for event in trace.get('events', []):\n",
    "        if 'terminal' in (event.get('type') or '').lower():\n",
    "            return 1\n",
    "        details = event.get('details', {})\n",
    "        if isinstance(details, dict) and ('terminal' in str(details).lower() or 'command' in str(details).lower()):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "def has_prompts(trace):\n",
    "    \"\"\"Check if trace contains prompts.\"\"\"\n",
    "    # Check prompts from companion data\n",
    "    if trace.get('prompts') and len(trace.get('prompts', [])) > 0:\n",
    "        return 1\n",
    "    # Also check events\n",
    "    for event in trace.get('events', []):\n",
    "        details = event.get('details', {})\n",
    "        if isinstance(details, dict) and 'prompt' in details:\n",
    "            return 1\n",
    "        if event.get('prompt'):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# Optimization: Skip raw rung (saves ~36 minutes) - uncomment if needed\n",
    "USE_RAW_RUNG = False  # Set to True if you need raw rung\n",
    "\n",
    "# Optimization: Cache rung extractions\n",
    "CACHE_FILE = RESULTS_DIR / 'rung_extractions_cache.pkl'\n",
    "USE_CACHE = True\n",
    "\n",
    "def process_single_trace(trace):\n",
    "    \"\"\"Process a single trace to extract features.\"\"\"\n",
    "    # Extract rung representations\n",
    "    rung_reps = {}\n",
    "    for rung_name, rung_func in RUNG_FUNCS.items():\n",
    "        # Skip raw if not needed (saves ~36 minutes)\n",
    "        if rung_name == 'raw' and not USE_RAW_RUNG:\n",
    "            continue\n",
    "        try:\n",
    "            rep = rung_func(trace)\n",
    "            rung_reps[rung_name] = rep if isinstance(rep, str) else ' '.join(rep) if isinstance(rep, list) else str(rep)\n",
    "        except Exception as e:\n",
    "            rung_reps[rung_name] = \"\"\n",
    "    \n",
    "    # Extract labels\n",
    "    code_changes = count_code_changes(trace)\n",
    "    unique_files = count_unique_files(trace)\n",
    "    has_terminal = has_terminal_activity(trace)\n",
    "    has_prompt = has_prompts(trace)\n",
    "    \n",
    "    return {\n",
    "        **rung_reps,\n",
    "        'code_changes': code_changes,\n",
    "        'unique_files': unique_files,\n",
    "        'has_terminal': has_terminal,\n",
    "        'has_prompt': has_prompt,\n",
    "    }\n",
    "\n",
    "# Check cache first\n",
    "if USE_CACHE and CACHE_FILE.exists():\n",
    "    print(f\"Loading cached rung extractions from {CACHE_FILE}...\")\n",
    "    try:\n",
    "        with open(CACHE_FILE, 'rb') as f:\n",
    "            cached_data = pickle.load(f)\n",
    "            if len(cached_data) == len(traces):\n",
    "                print(\"âœ“ Using cached rung extractions\")\n",
    "                rung_extractions = cached_data\n",
    "            else:\n",
    "                print(f\"âš  Cache size mismatch ({len(cached_data)} vs {len(traces)}), re-extracting...\")\n",
    "                rung_extractions = None\n",
    "    except Exception as e:\n",
    "        print(f\"âš  Cache load error: {e}, re-extracting...\")\n",
    "        rung_extractions = None\n",
    "else:\n",
    "    rung_extractions = None\n",
    "\n",
    "# Extract rungs (parallel or cached)\n",
    "if rung_extractions is None:\n",
    "    print(\"Building features (this may take a while)...\")\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    \n",
    "    # For programmatic execution (nbconvert), ALWAYS use sequential to avoid pickling errors\n",
    "    # Multiprocessing with notebook-defined functions fails in nbconvert due to pickling issues\n",
    "    # Even testing with Pool(1) can fail, so we skip parallel entirely for nbconvert\n",
    "    \n",
    "    # Check if we're in interactive Jupyter (only safe environment for multiprocessing)\n",
    "    USE_PARALLEL = False  # Default to sequential\n",
    "    \n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        ipython = get_ipython()\n",
    "        # Only use parallel if we're in a real interactive Jupyter kernel\n",
    "        if ipython is not None and hasattr(ipython, 'kernel') and ipython.kernel is not None:\n",
    "            # Check if we're NOT in nbconvert (nbconvert doesn't have a real kernel)\n",
    "            import sys\n",
    "            if 'nbconvert' not in ' '.join(sys.argv).lower():\n",
    "                USE_PARALLEL = True\n",
    "    except (ImportError, AttributeError):\n",
    "        pass\n",
    "    \n",
    "    # Always use sequential for safety - parallel causes pickling errors in nbconvert\n",
    "    USE_PARALLEL = False  # Force sequential for programmatic execution\n",
    "    \n",
    "    print(\"Using sequential processing (required for programmatic execution)\")\n",
    "    rung_extractions = [process_single_trace(trace) for trace in traces]\n",
    "    \n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    print(f\"âœ“ Extracted rungs in {elapsed:.2f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "    \n",
    "    # Save cache\n",
    "    if USE_CACHE:\n",
    "        print(f\"Saving cache to {CACHE_FILE}...\")\n",
    "        with open(CACHE_FILE, 'wb') as f:\n",
    "            pickle.dump(rung_extractions, f)\n",
    "        print(\"âœ“ Cache saved\")\n",
    "\n",
    "# Calculate median values for labels (needs all traces)\n",
    "print(\"Calculating label thresholds...\")\n",
    "all_code_changes = [r['code_changes'] for r in rung_extractions]\n",
    "all_unique_files = [r['unique_files'] for r in rung_extractions]\n",
    "median_code_changes = np.median(all_code_changes)\n",
    "median_unique_files = np.median(all_unique_files)\n",
    "\n",
    "# Build final features with labels\n",
    "print(\"Building final feature set...\")\n",
    "features = []\n",
    "for rung_data in rung_extractions:\n",
    "    feature_entry = {\n",
    "        **rung_data,\n",
    "        'high_code_activity': 1 if rung_data['code_changes'] > median_code_changes else 0,\n",
    "        'many_files': 1 if rung_data['unique_files'] > median_unique_files else 0,\n",
    "    }\n",
    "    features.append(feature_entry)\n",
    "\n",
    "print(f\"âœ“ Built features for {len(features)} traces\")\n",
    "\n",
    "# Define rungs to process (exclude raw if not needed) - used by all methods\n",
    "rungs_to_process = [r for r in RUNG_FUNCS.keys() if r != 'raw' or USE_RAW_RUNG]\n",
    "print(f\"âœ“ Processing {len(rungs_to_process)} rungs: {', '.join(rungs_to_process)}\")\n",
    "\n",
    "# Task labels for classification\n",
    "task_labels = [\n",
    "    ('high_code_activity', 'code_activity_classification'),\n",
    "    ('many_files', 'file_diversity_classification'),\n",
    "    ('has_terminal', 'terminal_usage_classification'),\n",
    "    ('has_prompt', 'prompt_usage_classification'),\n",
    "]\n",
    "\n",
    "print(f\"âœ“ Defined {len(task_labels)} classification tasks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: TF-IDF + Logistic Regression (Baseline)\n",
    "\n",
    "This is the baseline method from `probes_baseline.ipynb` - included for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Method 1 (TF-IDF + Logistic Regression) completed: 20 results\n"
     ]
    }
   ],
   "source": [
    "# Method 1: TF-IDF + Logistic Regression (Baseline)\n",
    "def build_tfidf_dataset(rung: str, label: str):\n",
    "    \"\"\"Build TF-IDF features for a given rung and label.\"\"\"\n",
    "    reps = [entry[rung] for entry in features]\n",
    "    placeholder = 'empty_repr'\n",
    "    cleaned = [repr if repr.strip() else placeholder for repr in reps]\n",
    "    vec = TfidfVectorizer(max_features=4096)\n",
    "    try:\n",
    "        X = vec.fit_transform(cleaned).toarray()\n",
    "    except ValueError:\n",
    "        X = np.zeros((len(cleaned), 1))\n",
    "    y = np.array([entry[label] for entry in features], dtype=int)\n",
    "    return X, y, vec\n",
    "\n",
    "all_results = []\n",
    "\n",
    "# Get rungs to process (exclude raw if not needed)\n",
    "rungs_to_process = [r for r in RUNG_FUNCS.keys() if r != 'raw' or USE_RAW_RUNG]\n",
    "\n",
    "for rung in rungs_to_process:\n",
    "    for label_name, task in task_labels:\n",
    "        X, y, vectorizer = build_tfidf_dataset(rung, label_name)\n",
    "        if len(np.unique(y)) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Train/test split for generalization\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        clf = LogisticRegression(max_iter=500, random_state=42)\n",
    "        start = time.perf_counter()\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_time = time.perf_counter() - start\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        infer_time = time.perf_counter() - start\n",
    "        \n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        train_f1 = f1_score(y_train, y_train_pred)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Model size (approximate)\n",
    "        model_size_mb = (clf.coef_.nbytes + clf.intercept_.nbytes) / (1024 * 1024)\n",
    "        \n",
    "        # Top features\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        coef_abs = np.abs(clf.coef_[0])\n",
    "        top_indices = np.argsort(coef_abs)[-15:][::-1]\n",
    "        top_features = {feature_names[i]: float(clf.coef_[0][i]) for i in top_indices}\n",
    "        \n",
    "        all_results.append({\n",
    "            'method': 'tfidf_logistic',\n",
    "            'rung': rung,\n",
    "            'task': task,\n",
    "            'train_accuracy': float(train_acc),\n",
    "            'test_accuracy': float(test_acc),\n",
    "            'train_f1': float(train_f1),\n",
    "            'test_f1': float(test_f1),\n",
    "            'train_time': train_time,\n",
    "            'infer_time': infer_time,\n",
    "            'model_size_mb': model_size_mb,\n",
    "            'n_features': X.shape[1],\n",
    "            'top_features': top_features,\n",
    "            'generalization_gap': float(train_acc - test_acc)\n",
    "        })\n",
    "\n",
    "print(f\"âœ“ Method 1 (TF-IDF + Logistic Regression) completed: {len([r for r in all_results if r['method'] == 'tfidf_logistic'])} results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Pre-trained Embeddings + Logistic Regression\n",
    "\n",
    "Uses `sentence-transformers` to encode representations into dense embeddings, then trains Logistic Regression on top.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained embedding model...\n",
      "âœ“ Model loaded\n",
      "  Encoding tokens / code_activity_classification...\n",
      "  Encoding tokens / file_diversity_classification...\n",
      "  Encoding tokens / terminal_usage_classification...\n",
      "  Encoding tokens / prompt_usage_classification...\n",
      "  Encoding semantic_edits / code_activity_classification...\n",
      "  Encoding semantic_edits / file_diversity_classification...\n",
      "  Encoding semantic_edits / terminal_usage_classification...\n",
      "  Encoding semantic_edits / prompt_usage_classification...\n",
      "  Encoding functions / code_activity_classification...\n",
      "  Encoding functions / file_diversity_classification...\n",
      "  Encoding functions / terminal_usage_classification...\n",
      "  Encoding functions / prompt_usage_classification...\n",
      "  Encoding motifs / code_activity_classification...\n",
      "  Encoding motifs / file_diversity_classification...\n",
      "  Encoding motifs / terminal_usage_classification...\n",
      "  Encoding motifs / prompt_usage_classification...\n",
      "  Encoding raw / code_activity_classification...\n",
      "  Encoding raw / file_diversity_classification...\n",
      "  Encoding raw / terminal_usage_classification...\n",
      "  Encoding raw / prompt_usage_classification...\n",
      "âœ“ Method 2 (Pre-trained Embeddings) completed: 20 results\n"
     ]
    }
   ],
   "source": [
    "# Method 2: Pre-trained Embeddings + Logistic Regression\n",
    "if HAS_SENTENCE_TRANSFORMERS:\n",
    "    print(\"Loading pre-trained embedding model...\")\n",
    "    embedding_model = SentenceTransformer('all-MiniLM-L6-v2')  # Fast, lightweight model\n",
    "    print(\"âœ“ Model loaded\")\n",
    "    \n",
    "    for rung in rungs_to_process:\n",
    "        for label_name, task in task_labels:\n",
    "            reps = [entry[rung] for entry in features]\n",
    "            y = np.array([entry[label_name] for entry in features], dtype=int)\n",
    "            if len(np.unique(y)) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Encode representations\n",
    "            print(f\"  Encoding {rung} / {task}...\")\n",
    "            start = time.perf_counter()\n",
    "            X = embedding_model.encode(reps, show_progress_bar=False)\n",
    "            encode_time = time.perf_counter() - start\n",
    "            \n",
    "            # Train/test split\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=0.2, random_state=42, stratify=y\n",
    "            )\n",
    "            \n",
    "            clf = LogisticRegression(max_iter=500, random_state=42)\n",
    "            start = time.perf_counter()\n",
    "            clf.fit(X_train, y_train)\n",
    "            train_time = time.perf_counter() - start\n",
    "            \n",
    "            start = time.perf_counter()\n",
    "            y_train_pred = clf.predict(X_train)\n",
    "            y_test_pred = clf.predict(X_test)\n",
    "            infer_time = time.perf_counter() - start\n",
    "            \n",
    "            train_acc = accuracy_score(y_train, y_train_pred)\n",
    "            test_acc = accuracy_score(y_test, y_test_pred)\n",
    "            train_f1 = f1_score(y_train, y_train_pred)\n",
    "            test_f1 = f1_score(y_test, y_test_pred)\n",
    "            \n",
    "            model_size_mb = (clf.coef_.nbytes + clf.intercept_.nbytes) / (1024 * 1024)\n",
    "            \n",
    "            all_results.append({\n",
    "                'method': 'pretrained_embeddings',\n",
    "                'rung': rung,\n",
    "                'task': task,\n",
    "                'train_accuracy': float(train_acc),\n",
    "                'test_accuracy': float(test_acc),\n",
    "                'train_f1': float(train_f1),\n",
    "                'test_f1': float(test_f1),\n",
    "                'train_time': train_time + encode_time,\n",
    "                'infer_time': infer_time,\n",
    "                'model_size_mb': model_size_mb,\n",
    "                'embedding_dim': X.shape[1],\n",
    "                'generalization_gap': float(train_acc - test_acc)\n",
    "            })\n",
    "    \n",
    "    print(f\"âœ“ Method 2 (Pre-trained Embeddings) completed: {len([r for r in all_results if r['method'] == 'pretrained_embeddings'])} results\")\n",
    "else:\n",
    "    print(\"âš  Skipping Method 2: sentence-transformers not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Random Forest\n",
    "\n",
    "Non-linear tree-based model with built-in feature importance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Method 3 (Random Forest) completed: 20 results\n"
     ]
    }
   ],
   "source": [
    "# Method 3: Random Forest\n",
    "for rung in rungs_to_process:\n",
    "    for label_name, task in task_labels:\n",
    "        X, y, vectorizer = build_tfidf_dataset(rung, label_name)\n",
    "        if len(np.unique(y)) < 2:\n",
    "            continue\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        clf = RandomForestClassifier(n_estimators=50, max_depth=10, random_state=42, n_jobs=-1)\n",
    "        start = time.perf_counter()\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_time = time.perf_counter() - start\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        infer_time = time.perf_counter() - start\n",
    "        \n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        train_f1 = f1_score(y_train, y_train_pred)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Feature importance\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        importances = clf.feature_importances_\n",
    "        top_indices = np.argsort(importances)[-15:][::-1]\n",
    "        top_features = {feature_names[i]: float(importances[i]) for i in top_indices}\n",
    "        \n",
    "        all_results.append({\n",
    "            'method': 'random_forest',\n",
    "            'rung': rung,\n",
    "            'task': task,\n",
    "            'train_accuracy': float(train_acc),\n",
    "            'test_accuracy': float(test_acc),\n",
    "            'train_f1': float(train_f1),\n",
    "            'test_f1': float(test_f1),\n",
    "            'train_time': train_time,\n",
    "            'infer_time': infer_time,\n",
    "            'n_estimators': 50,\n",
    "            'max_depth': 10,\n",
    "            'top_features': top_features,\n",
    "            'generalization_gap': float(train_acc - test_acc)\n",
    "        })\n",
    "\n",
    "print(f\"âœ“ Method 3 (Random Forest) completed: {len([r for r in all_results if r['method'] == 'random_forest'])} results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 4: Gradient Boosting\n",
    "\n",
    "Sequential ensemble method that builds trees iteratively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Method 4 (Gradient Boosting) completed: 20 results\n"
     ]
    }
   ],
   "source": [
    "# Method 4: Gradient Boosting\n",
    "for rung in rungs_to_process:\n",
    "    for label_name, task in task_labels:\n",
    "        X, y, vectorizer = build_tfidf_dataset(rung, label_name)\n",
    "        if len(np.unique(y)) < 2:\n",
    "            continue\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        clf = GradientBoostingClassifier(n_estimators=50, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "        start = time.perf_counter()\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_time = time.perf_counter() - start\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        infer_time = time.perf_counter() - start\n",
    "        \n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        train_f1 = f1_score(y_train, y_train_pred)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "        \n",
    "        # Feature importance\n",
    "        feature_names = vectorizer.get_feature_names_out()\n",
    "        importances = clf.feature_importances_\n",
    "        top_indices = np.argsort(importances)[-15:][::-1]\n",
    "        top_features = {feature_names[i]: float(importances[i]) for i in top_indices}\n",
    "        \n",
    "        all_results.append({\n",
    "            'method': 'gradient_boosting',\n",
    "            'rung': rung,\n",
    "            'task': task,\n",
    "            'train_accuracy': float(train_acc),\n",
    "            'test_accuracy': float(test_acc),\n",
    "            'train_f1': float(train_f1),\n",
    "            'test_f1': float(test_f1),\n",
    "            'train_time': train_time,\n",
    "            'infer_time': infer_time,\n",
    "            'n_estimators': 50,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_depth': 5,\n",
    "            'top_features': top_features,\n",
    "            'generalization_gap': float(train_acc - test_acc)\n",
    "        })\n",
    "\n",
    "print(f\"âœ“ Method 4 (Gradient Boosting) completed: {len([r for r in all_results if r['method'] == 'gradient_boosting'])} results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 5: Lightweight MLP\n",
    "\n",
    "Small neural network with early stopping for efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Method 5 (MLP) completed: 20 results\n"
     ]
    }
   ],
   "source": [
    "# Method 5: Lightweight MLP\n",
    "for rung in rungs_to_process:\n",
    "    for label_name, task in task_labels:\n",
    "        X, y, vectorizer = build_tfidf_dataset(rung, label_name)\n",
    "        if len(np.unique(y)) < 2:\n",
    "            continue\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "        \n",
    "        clf = MLPClassifier(\n",
    "            hidden_layer_sizes=(64,),\n",
    "            activation='relu',\n",
    "            max_iter=500,\n",
    "            early_stopping=True,\n",
    "            validation_fraction=0.1,\n",
    "            random_state=42\n",
    "        )\n",
    "        start = time.perf_counter()\n",
    "        clf.fit(X_train, y_train)\n",
    "        train_time = time.perf_counter() - start\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_test_pred = clf.predict(X_test)\n",
    "        infer_time = time.perf_counter() - start\n",
    "        \n",
    "        train_acc = accuracy_score(y_train, y_train_pred)\n",
    "        test_acc = accuracy_score(y_test, y_test_pred)\n",
    "        train_f1 = f1_score(y_train, y_train_pred)\n",
    "        test_f1 = f1_score(y_test, y_test_pred)\n",
    "        \n",
    "        all_results.append({\n",
    "            'method': 'mlp',\n",
    "            'rung': rung,\n",
    "            'task': task,\n",
    "            'train_accuracy': float(train_acc),\n",
    "            'test_accuracy': float(test_acc),\n",
    "            'train_f1': float(train_f1),\n",
    "            'test_f1': float(test_f1),\n",
    "            'train_time': train_time,\n",
    "            'infer_time': infer_time,\n",
    "            'hidden_layer_sizes': (64,),\n",
    "            'n_iterations': clf.n_iter_,\n",
    "            'generalization_gap': float(train_acc - test_acc)\n",
    "        })\n",
    "\n",
    "print(f\"âœ“ Method 5 (MLP) completed: {len([r for r in all_results if r['method'] == 'mlp'])} results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Visualizations\n",
    "\n",
    "Visualize Random Forest trees for interpretability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 228 is out of bounds for axis 0 with size 20",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     18\u001b[39m fig, axes = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m3\u001b[39m, figsize=(\u001b[32m30\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, tree \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(clf_viz.estimators_):\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[43mplot_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilled\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvectorizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_feature_names_out\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m             \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontsize\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     axes[i].set_title(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mTree \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, fontsize=\u001b[32m12\u001b[39m, fontweight=\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     24\u001b[39m plt.suptitle(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRandom Forest Trees: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrung_viz\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m / \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtask_viz\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m, fontsize=\u001b[32m14\u001b[39m, fontweight=\u001b[33m'\u001b[39m\u001b[33mbold\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/new_cursor/venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/new_cursor/venv/lib/python3.13/site-packages/sklearn/tree/_export.py:205\u001b[39m, in \u001b[36mplot_tree\u001b[39m\u001b[34m(decision_tree, max_depth, feature_names, class_names, label, filled, impurity, node_ids, proportion, rounded, precision, ax, fontsize)\u001b[39m\n\u001b[32m    190\u001b[39m check_is_fitted(decision_tree)\n\u001b[32m    192\u001b[39m exporter = _MPLTreeExporter(\n\u001b[32m    193\u001b[39m     max_depth=max_depth,\n\u001b[32m    194\u001b[39m     feature_names=feature_names,\n\u001b[32m   (...)\u001b[39m\u001b[32m    203\u001b[39m     fontsize=fontsize,\n\u001b[32m    204\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mexporter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43max\u001b[49m\u001b[43m=\u001b[49m\u001b[43max\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/new_cursor/venv/lib/python3.13/site-packages/sklearn/tree/_export.py:652\u001b[39m, in \u001b[36m_MPLTreeExporter.export\u001b[39m\u001b[34m(self, decision_tree, ax)\u001b[39m\n\u001b[32m    650\u001b[39m ax.clear()\n\u001b[32m    651\u001b[39m ax.set_axis_off()\n\u001b[32m--> \u001b[39m\u001b[32m652\u001b[39m my_tree = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_tree\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecision_tree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    653\u001b[39m draw_tree = buchheim(my_tree)\n\u001b[32m    655\u001b[39m \u001b[38;5;66;03m# important to make sure we're still\u001b[39;00m\n\u001b[32m    656\u001b[39m \u001b[38;5;66;03m# inside the axis after drawing the box\u001b[39;00m\n\u001b[32m    657\u001b[39m \u001b[38;5;66;03m# this makes sense because the width of a box\u001b[39;00m\n\u001b[32m    658\u001b[39m \u001b[38;5;66;03m# is about the same as the distance between boxes\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/new_cursor/venv/lib/python3.13/site-packages/sklearn/tree/_export.py:633\u001b[39m, in \u001b[36m_MPLTreeExporter._make_tree\u001b[39m\u001b[34m(self, node_id, et, criterion, depth)\u001b[39m\n\u001b[32m    628\u001b[39m name = \u001b[38;5;28mself\u001b[39m.node_to_str(et, node_id, criterion=criterion)\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m et.children_left[node_id] != _tree.TREE_LEAF \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    630\u001b[39m     \u001b[38;5;28mself\u001b[39m.max_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m depth <= \u001b[38;5;28mself\u001b[39m.max_depth\n\u001b[32m    631\u001b[39m ):\n\u001b[32m    632\u001b[39m     children = [\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_tree\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[43m            \u001b[49m\u001b[43met\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchildren_left\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43met\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    635\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    636\u001b[39m         \u001b[38;5;28mself\u001b[39m._make_tree(\n\u001b[32m    637\u001b[39m             et.children_right[node_id], et, criterion, depth=depth + \u001b[32m1\u001b[39m\n\u001b[32m    638\u001b[39m         ),\n\u001b[32m    639\u001b[39m     ]\n\u001b[32m    640\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Tree(name, node_id)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/new_cursor/venv/lib/python3.13/site-packages/sklearn/tree/_export.py:628\u001b[39m, in \u001b[36m_MPLTreeExporter._make_tree\u001b[39m\u001b[34m(self, node_id, et, criterion, depth)\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_tree\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_id, et, criterion, depth=\u001b[32m0\u001b[39m):\n\u001b[32m    626\u001b[39m     \u001b[38;5;66;03m# traverses _tree.Tree recursively, builds intermediate\u001b[39;00m\n\u001b[32m    627\u001b[39m     \u001b[38;5;66;03m# \"_reingold_tilford.Tree\" object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m628\u001b[39m     name = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnode_to_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43met\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    629\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m et.children_left[node_id] != _tree.TREE_LEAF \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    630\u001b[39m         \u001b[38;5;28mself\u001b[39m.max_depth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m depth <= \u001b[38;5;28mself\u001b[39m.max_depth\n\u001b[32m    631\u001b[39m     ):\n\u001b[32m    632\u001b[39m         children = [\n\u001b[32m    633\u001b[39m             \u001b[38;5;28mself\u001b[39m._make_tree(\n\u001b[32m    634\u001b[39m                 et.children_left[node_id], et, criterion, depth=depth + \u001b[32m1\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    638\u001b[39m             ),\n\u001b[32m    639\u001b[39m         ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/new_cursor/venv/lib/python3.13/site-packages/sklearn/tree/_export.py:310\u001b[39m, in \u001b[36m_BaseTreeExporter.node_to_str\u001b[39m\u001b[34m(self, tree, node_id, criterion)\u001b[39m\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tree.children_left[node_id] != _tree.TREE_LEAF:\n\u001b[32m    308\u001b[39m     \u001b[38;5;66;03m# Always write node decision criteria, except for leaves\u001b[39;00m\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.feature_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m         feature = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnode_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    311\u001b[39m         feature = \u001b[38;5;28mself\u001b[39m.str_escape(feature)\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mIndexError\u001b[39m: index 228 is out of bounds for axis 0 with size 20"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3000x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tree Visualizations (for a specific rung/task combination)\n",
    "# Uses graphviz for tree visualization (alternative to matplotlib)\n",
    "\n",
    "try:\n",
    "    from graphviz import Source\n",
    "    from sklearn.tree import export_graphviz\n",
    "    import subprocess\n",
    "    # Check if graphviz system package is installed\n",
    "    try:\n",
    "        subprocess.run(['dot', '-V'], capture_output=True, check=True)\n",
    "        HAS_GRAPHVIZ = True\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        HAS_GRAPHVIZ = False\n",
    "        print(\"âš  graphviz Python package installed, but system package not found.\")\n",
    "        print(\"   Install system package: brew install graphviz (macOS) or apt-get install graphviz (Linux)\")\n",
    "        print(\"   Falling back to text representation.\")\n",
    "except ImportError:\n",
    "    HAS_GRAPHVIZ = False\n",
    "    print(\"âš  graphviz not available. Install with: pip install graphviz\")\n",
    "    print(\"   Also install system package: brew install graphviz (macOS) or apt-get install graphviz (Linux)\")\n",
    "    print(\"   Falling back to text representation.\")\n",
    "\n",
    "rung_viz = 'motifs'\n",
    "task_viz = 'code_activity_classification'\n",
    "label_viz = 'high_code_activity'\n",
    "\n",
    "X, y, vectorizer = build_tfidf_dataset(rung_viz, label_viz)\n",
    "if len(np.unique(y)) >= 2:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Small forest for visualization\n",
    "    clf_viz = RandomForestClassifier(n_estimators=3, max_depth=4, random_state=42)\n",
    "    clf_viz.fit(X_train, y_train)\n",
    "    \n",
    "    # Visualize trees using graphviz\n",
    "    if HAS_GRAPHVIZ:\n",
    "        feature_names = list(vectorizer.get_feature_names_out()[:20])\n",
    "        class_names = [str(i) for i in range(len(np.unique(y_train)))]\n",
    "        \n",
    "        # Create tree visualizations\n",
    "        tree_graphs = []\n",
    "        for i, tree in enumerate(clf_viz.estimators_):\n",
    "            # Export tree to graphviz format\n",
    "            dot_data = export_graphviz(\n",
    "                tree,\n",
    "                out_file=None,\n",
    "                feature_names=feature_names,\n",
    "                class_names=class_names,\n",
    "                filled=True,\n",
    "                rounded=True,\n",
    "                special_characters=True,\n",
    "                max_depth=3,\n",
    "                fontsize=10\n",
    "            )\n",
    "            \n",
    "            # Create graphviz Source object\n",
    "            graph = Source(dot_data)\n",
    "            \n",
    "            # Save as PNG\n",
    "            output_path = RESULTS_DIR / f'random_forest_tree_{i+1}.png'\n",
    "            graph.render(filename=str(output_path.with_suffix('')), format='png', cleanup=True)\n",
    "            print(f\"âœ“ Saved tree {i+1} visualization to {output_path}\")\n",
    "            \n",
    "            tree_graphs.append(graph)\n",
    "        \n",
    "        # Display trees in notebook\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Random Forest Trees: {rung_viz} / {task_viz}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        for i, graph in enumerate(tree_graphs):\n",
    "            print(f\"\\nTree {i+1}:\")\n",
    "            print(\"-\" * 70)\n",
    "            graph  # Display in notebook\n",
    "        \n",
    "        # Also save combined visualization if possible\n",
    "        print(f\"\\nâœ“ All tree visualizations saved to {RESULTS_DIR}\")\n",
    "    else:\n",
    "        # Fallback: Enhanced text representation\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Random Forest Trees: {rung_viz} / {task_viz}\")\n",
    "        print(f\"{'='*70}\\n\")\n",
    "        \n",
    "        feature_names = list(vectorizer.get_feature_names_out()[:20])\n",
    "        for i, tree in enumerate(clf_viz.estimators_):\n",
    "            print(f\"\\n{'='*70}\")\n",
    "            print(f\"Tree {i+1} (Text Representation):\")\n",
    "            print(f\"{'='*70}\")\n",
    "            print(export_text(tree, feature_names=feature_names, max_depth=3))\n",
    "            print()\n",
    "    \n",
    "    # Text representation of first tree (always show)\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"Detailed Text Representation of First Tree:\")\n",
    "    print(f\"{'='*70}\")\n",
    "    feature_names = list(vectorizer.get_feature_names_out()[:20])\n",
    "    print(export_text(clf_viz.estimators_[0], feature_names=feature_names, max_depth=3))\n",
    "else:\n",
    "    print(f\"âš  Cannot visualize: insufficient classes for {rung_viz} / {task_viz}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Comparison\n",
    "\n",
    "Compare top features across different methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Comparison\n",
    "# Compare top features for a specific rung/task\n",
    "rung_comp = 'motifs'\n",
    "task_comp = 'code_activity_classification'\n",
    "label_comp = 'high_code_activity'\n",
    "\n",
    "comparison_data = []\n",
    "for result in all_results:\n",
    "    if result['rung'] == rung_comp and result['task'] == task_comp and 'top_features' in result:\n",
    "        method = result['method']\n",
    "        top_features = result['top_features']\n",
    "        for feature, importance in list(top_features.items())[:15]:\n",
    "            comparison_data.append({\n",
    "                'method': method,\n",
    "                'feature': feature,\n",
    "                'importance': importance\n",
    "            })\n",
    "\n",
    "if comparison_data:\n",
    "    comp_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Get top 15 features per method\n",
    "    methods = comp_df['method'].unique()\n",
    "    \n",
    "    # Create charts for each method\n",
    "    charts = []\n",
    "    for method in methods:\n",
    "        method_data = comp_df[comp_df['method'] == method].nlargest(15, 'importance').sort_values('importance')\n",
    "        chart = alt.Chart(method_data).mark_bar(opacity=0.7, cornerRadius=4).encode(\n",
    "            x=alt.X('importance:Q', title='Importance', axis=alt.Axis(titleFontWeight='bold')),\n",
    "            y=alt.Y('feature:N', title='Feature', sort=alt.SortField('importance', order='ascending'), \n",
    "                   axis=alt.Axis(titleFontWeight='bold', labelFontSize=9)),\n",
    "            tooltip=['feature', alt.Tooltip('importance:Q', format='.4f')],\n",
    "        ).properties(\n",
    "            width=400,\n",
    "            height=300,\n",
    "            title=alt.TitleParams(text=f'{method.replace(\"_\", \" \").title()}: Top 15 Features', \n",
    "                                fontWeight='bold', fontSize=14)\n",
    "        )\n",
    "        # Don't configure individual charts - will configure the dashboard\n",
    "        charts.append(chart)\n",
    "    \n",
    "    # Combine charts vertically\n",
    "    if len(charts) > 1:\n",
    "        combined = alt.vconcat(*charts, spacing=30).configure_axis(gridOpacity=0.3)\n",
    "    else:\n",
    "        combined = charts[0].configure_axis(gridOpacity=0.3)\n",
    "    \n",
    "    # Save chart\n",
    "    save_chart(combined, RESULTS_DIR / 'feature_importance_comparison.png', scale_factor=2.0)\n",
    "    print(f\"âœ“ Saved feature importance comparison to {RESULTS_DIR / 'feature_importance_comparison.png'}\")\n",
    "    \n",
    "    combined\n",
    "else:\n",
    "    print(\"âš  No feature importance data available for comparison\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method Comparison: Performance & Efficiency\n",
    "\n",
    "Compare all methods across accuracy, training time, model size, and generalization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method Comparison: Performance & Efficiency\n",
    "df_all = pd.DataFrame(all_results)\n",
    "\n",
    "# Save all results to JSONL\n",
    "output_file = RESULTS_DIR / 'advanced_probes_comparison.jsonl'\n",
    "with output_file.open('w') as f:\n",
    "    for result in all_results:\n",
    "        # Convert numpy types to native Python types for JSON\n",
    "        json_result = json.loads(json.dumps(result, default=str))\n",
    "        f.write(json.dumps(json_result) + '\\n')\n",
    "print(f\"âœ“ Saved all results to {output_file}\")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"METHOD COMPARISON SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGrouped by method:\")\n",
    "summary = df_all.groupby('method').agg({\n",
    "    'test_accuracy': ['mean', 'std'],\n",
    "    'test_f1': ['mean', 'std'],\n",
    "    'train_time': ['mean', 'std'],\n",
    "    'generalization_gap': ['mean', 'std']\n",
    "}).round(4)\n",
    "print(summary)\n",
    "\n",
    "# Visualization: 4-panel comparison using Altair\n",
    "# 1. Test Accuracy\n",
    "method_acc = df_all.groupby('method')['test_accuracy'].mean().sort_values(ascending=False).reset_index()\n",
    "method_acc['method_label'] = method_acc['method'].str.replace('_', ' ').str.title()\n",
    "chart1 = alt.Chart(method_acc).mark_bar(opacity=0.7, cornerRadius=4, color=COLOR_PALETTE[0]).encode(\n",
    "    x=alt.X('method_label:N', title='Method', sort=alt.SortField('test_accuracy', order='descending'),\n",
    "           axis=alt.Axis(labelAngle=-45, titleFontWeight='bold')),\n",
    "    y=alt.Y('test_accuracy:Q', title='Mean Test Accuracy', axis=alt.Axis(titleFontWeight='bold')),\n",
    "    tooltip=['method_label', alt.Tooltip('test_accuracy:Q', format='.3f')],\n",
    ").properties(\n",
    "    width=300, height=250,\n",
    "    title=alt.TitleParams(text='Test Accuracy by Method', fontWeight='bold', fontSize=14)\n",
    ")\n",
    "# Don't configure individual charts - will configure the dashboard\n",
    "\n",
    "# 2. Training Time\n",
    "method_time = df_all.groupby('method')['train_time'].mean().sort_values(ascending=True).reset_index()\n",
    "method_time['method_label'] = method_time['method'].str.replace('_', ' ').str.title()\n",
    "chart2 = alt.Chart(method_time).mark_bar(opacity=0.7, cornerRadius=4, color=COLOR_PALETTE[1]).encode(\n",
    "    x=alt.X('train_time:Q', title='Mean Training Time (seconds)', axis=alt.Axis(titleFontWeight='bold')),\n",
    "    y=alt.Y('method_label:N', title='Method', sort=alt.SortField('train_time', order='ascending'),\n",
    "           axis=alt.Axis(titleFontWeight='bold')),\n",
    "    tooltip=['method_label', alt.Tooltip('train_time:Q', format='.4f')],\n",
    ").properties(\n",
    "    width=300, height=250,\n",
    "    title=alt.TitleParams(text='Training Time by Method', fontWeight='bold', fontSize=14)\n",
    ")\n",
    "# Don't configure individual charts - will configure the dashboard\n",
    "\n",
    "# 3. Model Size (where available)\n",
    "if 'model_size_mb' in df_all.columns:\n",
    "    method_size = df_all[df_all['model_size_mb'].notna()].groupby('method')['model_size_mb'].mean().sort_values(ascending=True).reset_index()\n",
    "    if not method_size.empty:\n",
    "        method_size['method_label'] = method_size['method'].str.replace('_', ' ').str.title()\n",
    "        chart3 = alt.Chart(method_size).mark_bar(opacity=0.7, cornerRadius=4, color=COLOR_PALETTE[2]).encode(\n",
    "            x=alt.X('model_size_mb:Q', title='Mean Model Size (MB)', axis=alt.Axis(titleFontWeight='bold')),\n",
    "            y=alt.Y('method_label:N', title='Method', sort=alt.SortField('model_size_mb', order='ascending'),\n",
    "                   axis=alt.Axis(titleFontWeight='bold')),\n",
    "            tooltip=['method_label', alt.Tooltip('model_size_mb:Q', format='.4f')],\n",
    "        ).properties(\n",
    "            width=300, height=250,\n",
    "            title=alt.TitleParams(text='Model Size by Method', fontWeight='bold', fontSize=14)\n",
    "        )\n",
    "        # Don't configure individual charts - will configure the dashboard\n",
    "    else:\n",
    "        chart3 = alt.Chart(pd.DataFrame({'text': ['Model size data not available']})).mark_text(\n",
    "            fontSize=14\n",
    "        ).encode(text='text:N').properties(\n",
    "            width=300, height=250,\n",
    "            title=alt.TitleParams(text='Model Size by Method', fontWeight='bold', fontSize=14)\n",
    "        )\n",
    "else:\n",
    "    chart3 = alt.Chart(pd.DataFrame({'text': ['Model size data not available']})).mark_text(\n",
    "        fontSize=14\n",
    "    ).encode(text='text:N').properties(\n",
    "        width=300, height=250,\n",
    "        title=alt.TitleParams(text='Model Size by Method', fontWeight='bold', fontSize=14)\n",
    "    )\n",
    "\n",
    "# 4. Generalization Gap\n",
    "method_gap = df_all.groupby('method')['generalization_gap'].mean().sort_values(ascending=True).reset_index()\n",
    "method_gap['method_label'] = method_gap['method'].str.replace('_', ' ').str.title()\n",
    "chart4 = alt.Chart(method_gap).mark_bar(opacity=0.7, cornerRadius=4, color=COLOR_PALETTE[3]).encode(\n",
    "    x=alt.X('generalization_gap:Q', title='Mean Generalization Gap (Train - Test)', \n",
    "           axis=alt.Axis(titleFontWeight='bold')),\n",
    "    y=alt.Y('method_label:N', title='Method', sort=alt.SortField('generalization_gap', order='ascending'),\n",
    "           axis=alt.Axis(titleFontWeight='bold')),\n",
    "    tooltip=['method_label', alt.Tooltip('generalization_gap:Q', format='.4f')],\n",
    ").properties(\n",
    "    width=300, height=250,\n",
    "    title=alt.TitleParams(text='Overfitting Measure (Lower = Better)', fontWeight='bold', fontSize=14)\n",
    ")\n",
    "# Don't configure individual charts - will configure the dashboard\n",
    "\n",
    "# Combine into dashboard\n",
    "top_row = alt.hconcat(chart1, chart2, spacing=20)\n",
    "bottom_row = alt.hconcat(chart3, chart4, spacing=20)\n",
    "dashboard = alt.vconcat(top_row, bottom_row, spacing=30).configure(\n",
    "    view={'continuousWidth': 300, 'continuousHeight': 250},\n",
    "    axis={'labelFontSize': 11, 'titleFontSize': 12, 'titleFontWeight': 'bold', 'gridOpacity': 0.3},\n",
    "    title={'fontSize': 16, 'fontWeight': 'bold'},\n",
    ").properties(\n",
    "    title=alt.TitleParams(text='Advanced Probes: Method Comparison', fontWeight='bold', fontSize=16)\n",
    ")\n",
    "\n",
    "# Save chart\n",
    "save_chart(dashboard, RESULTS_DIR / 'method_comparison_summary.png', scale_factor=2.0)\n",
    "print(f\"\\nâœ“ Saved method comparison to {RESULTS_DIR / 'method_comparison_summary.png'}\")\n",
    "\n",
    "dashboard\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BEST METHODS BY METRIC\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Best Test Accuracy: {df_all.loc[df_all['test_accuracy'].idxmax(), 'method']} ({df_all['test_accuracy'].max():.4f})\")\n",
    "print(f\"Fastest Training: {df_all.loc[df_all['train_time'].idxmin(), 'method']} ({df_all['train_time'].min():.4f}s)\")\n",
    "if 'model_size_mb' in df_all.columns:\n",
    "    size_data = df_all[df_all['model_size_mb'].notna()]\n",
    "    if not size_data.empty:\n",
    "        print(f\"Smallest Model: {size_data.loc[size_data['model_size_mb'].idxmin(), 'method']} ({size_data['model_size_mb'].min():.4f} MB)\")\n",
    "print(f\"Best Generalization (lowest gap): {df_all.loc[df_all['generalization_gap'].idxmin(), 'method']} ({df_all['generalization_gap'].min():.4f})\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
