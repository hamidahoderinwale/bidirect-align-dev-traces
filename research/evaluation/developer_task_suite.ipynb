{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Developer Task Suite\n",
        "\n",
        "This notebook defines a comprehensive suite of real-world developer tasks and maps them to:\n",
        "- **Evaluation Metrics**: How to measure task performance\n",
        "- **Expected Best Rungs**: Which representation rungs should work best\n",
        "- **Implementation Status**: What's been implemented and what's pending\n",
        "\n",
        "## Purpose\n",
        "\n",
        "This is a **reference/planning document** (not an execution notebook). It serves as:\n",
        "1. **Task Catalog**: Complete list of developer tasks we want to evaluate\n",
        "2. **Evaluation Guide**: Metrics and methods for each task\n",
        "3. **Rung Selection**: Expected best rungs based on task characteristics\n",
        "4. **Progress Tracker**: Implementation status across the research pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Representation Rungs\n",
        "\n",
        "Our privacy-preserving abstraction ladder has 6 rungs:\n",
        "\n",
        "1. **tokens** (Rung 1): Token-level with PII redaction - exact text changes, lowest privacy\n",
        "2. **semantic_edits** (Rung 2): AST-based edit operations - intent without raw code\n",
        "3. **functions** (Rung 3): Function signatures and module-level changes\n",
        "4. **files** (Rung 4): File-level collaboration graph with action counts\n",
        "5. **dependencies** (Rung 5): Dependency graph - import relationships\n",
        "6. **motifs** (Rung 6): Workflow patterns and high-level sequences - highest abstraction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional\n",
        "from dataclasses import dataclass, asdict\n",
        "from enum import Enum\n",
        "\n",
        "class TaskStatus(Enum):\n",
        "    NOT_STARTED = \"not_started\"\n",
        "    IN_PROGRESS = \"in_progress\"\n",
        "    COMPLETE = \"complete\"\n",
        "    PARTIAL = \"partial\"\n",
        "\n",
        "class TaskCategory(Enum):\n",
        "    RETRIEVAL = \"retrieval\"\n",
        "    PREDICTION = \"prediction\"\n",
        "    CLASSIFICATION = \"classification\"\n",
        "    SEARCH = \"search\"\n",
        "    SEGMENTATION = \"segmentation\"\n",
        "    ANALYSIS = \"analysis\"\n",
        "\n",
        "@dataclass\n",
        "class DeveloperTask:\n",
        "    \"\"\"Represents a developer task with evaluation details.\"\"\"\n",
        "    id: str\n",
        "    name: str\n",
        "    description: str\n",
        "    category: TaskCategory\n",
        "    metrics: List[str]\n",
        "    expected_best_rungs: List[str]\n",
        "    rationale: str\n",
        "    status: TaskStatus\n",
        "    implementation_file: Optional[str] = None\n",
        "    results_file: Optional[str] = None\n",
        "    notes: Optional[str] = None\n",
        "    \n",
        "    def to_dict(self):\n",
        "        d = asdict(self)\n",
        "        d['category'] = self.category.value\n",
        "        d['status'] = self.status.value\n",
        "        return d\n",
        "\n",
        "# Initialize task suite\n",
        "tasks: List[DeveloperTask] = []\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task Suite Definition\n",
        "\n",
        "### Category 1: Context Retrieval Tasks\n",
        "\n",
        "Tasks that involve finding relevant code/context for a given prompt or task.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Context Retrieval: Find relevant files/snippets for a prompt\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"context_retrieval\",\n",
        "    name=\"Context Retrieval\",\n",
        "    description=\"Given a prompt/task, retrieve the most relevant files and code snippets from the codebase\",\n",
        "    category=TaskCategory.RETRIEVAL,\n",
        "    metrics=[\"MRR\", \"recall@1\", \"recall@5\", \"recall@10\", \"precision@k\", \"representation_size\"],\n",
        "    expected_best_rungs=[\"semantic_edits\", \"functions\", \"files\"],\n",
        "    rationale=\"Semantic edits capture intent, functions provide structure, files show scope\",\n",
        "    status=TaskStatus.COMPLETE,\n",
        "    implementation_file=\"research/evaluation/retrieval/context_retrieval.ipynb\",\n",
        "    results_file=\"research/results/context_retrieval_performance.png\",\n",
        "    notes=\"Implemented with TF-IDF retrieval across all rungs\"\n",
        "))\n",
        "\n",
        "# File-level Context: Find files that should be in context window\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"file_context_retrieval\",\n",
        "    name=\"File-level Context Retrieval\",\n",
        "    description=\"Retrieve files that should be included in context window for a given task\",\n",
        "    category=TaskCategory.RETRIEVAL,\n",
        "    metrics=[\"MRR\", \"recall@k\", \"file_coverage\", \"dependency_accuracy\"],\n",
        "    expected_best_rungs=[\"files\", \"dependencies\", \"functions\"],\n",
        "    rationale=\"File and dependency graphs capture structural relationships\",\n",
        "    status=TaskStatus.COMPLETE,\n",
        "    implementation_file=\"research/evaluation/retrieval/context_retrieval.ipynb\",\n",
        "    results_file=\"research/results/context_file_actions.png\",\n",
        "    notes=\"Part of context_retrieval evaluation\"\n",
        "))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Category 2: Prediction Tasks\n",
        "\n",
        "Tasks that predict future events or actions based on current context.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Next Event Prediction: Predict the next action/event\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"next_event_prediction\",\n",
        "    name=\"Next Event Prediction\",\n",
        "    description=\"Predict the next event (code change, file navigation, terminal command) given current context\",\n",
        "    category=TaskCategory.PREDICTION,\n",
        "    metrics=[\"accuracy\", \"top_k_accuracy\", \"perplexity\", \"cross_entropy\"],\n",
        "    expected_best_rungs=[\"semantic_edits\", \"functions\", \"motifs\"],\n",
        "    rationale=\"Semantic edits show immediate patterns, functions show structure, motifs show workflow\",\n",
        "    status=TaskStatus.COMPLETE,\n",
        "    implementation_file=\"research/evaluation/probes/probes_baseline.ipynb\",\n",
        "    results_file=\"research/results/probe_metrics.json\",\n",
        "    notes=\"Implemented as classification probe in probes_baseline\"\n",
        "))\n",
        "\n",
        "# Next File Prediction: Predict which file will be edited next\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"next_file_prediction\",\n",
        "    name=\"Next File Prediction\",\n",
        "    description=\"Predict which file the developer will edit next based on current session\",\n",
        "    category=TaskCategory.PREDICTION,\n",
        "    metrics=[\"accuracy\", \"recall@k\", \"file_rank\"],\n",
        "    expected_best_rungs=[\"files\", \"dependencies\", \"motifs\"],\n",
        "    rationale=\"File relationships and workflow patterns predict next file\",\n",
        "    status=TaskStatus.PARTIAL,\n",
        "    implementation_file=\"research/evaluation/probes/probes_baseline.ipynb\",\n",
        "    notes=\"Can be derived from next_event_prediction with file filtering\"\n",
        "))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Category 3: Classification Tasks\n",
        "\n",
        "Tasks that classify or categorize developer activities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Activity Classification: Classify type of coding activity\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"activity_classification\",\n",
        "    name=\"Activity Classification\",\n",
        "    description=\"Classify the type of coding activity (feature addition, bug fix, refactoring, etc.)\",\n",
        "    category=TaskCategory.CLASSIFICATION,\n",
        "    metrics=[\"accuracy\", \"f1_score\", \"per_class_f1\", \"confusion_matrix\"],\n",
        "    expected_best_rungs=[\"semantic_edits\", \"functions\", \"motifs\"],\n",
        "    rationale=\"Semantic edits show change patterns, functions show scope, motifs show workflow intent\",\n",
        "    status=TaskStatus.COMPLETE,\n",
        "    implementation_file=\"research/evaluation/probes/probes_baseline.ipynb\",\n",
        "    results_file=\"research/results/classification_accuracy_by_rung.png\",\n",
        "    notes=\"Implemented as multi-class classification probe\"\n",
        "))\n",
        "\n",
        "# Intent Classification: Classify developer intent\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"intent_classification\",\n",
        "    name=\"Intent Classification\",\n",
        "    description=\"Classify developer intent (DEBUG, FEATURE, REFACTOR, etc.) from activity patterns\",\n",
        "    category=TaskCategory.CLASSIFICATION,\n",
        "    metrics=[\"accuracy\", \"f1_score\", \"intent_aware_metrics\"],\n",
        "    expected_best_rungs=[\"motifs\", \"semantic_edits\", \"functions\"],\n",
        "    rationale=\"Motifs capture high-level workflow patterns that indicate intent\",\n",
        "    status=TaskStatus.COMPLETE,\n",
        "    implementation_file=\"research/evaluation/probes/probes_baseline.ipynb\",\n",
        "    results_file=\"research/results/probe_metrics_intent_aware.json\",\n",
        "    notes=\"Intent-aware probe evaluation implemented\"\n",
        "))\n",
        "\n",
        "# Anomaly Detection: Detect unusual or suspicious patterns\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"anomaly_detection\",\n",
        "    name=\"Anomaly Detection\",\n",
        "    description=\"Detect anomalous or unusual developer activity patterns\",\n",
        "    category=TaskCategory.CLASSIFICATION,\n",
        "    metrics=[\"precision\", \"recall\", \"f1_score\", \"roc_auc\", \"anomaly_score_distribution\"],\n",
        "    expected_best_rungs=[\"motifs\", \"semantic_edits\", \"functions\"],\n",
        "    rationale=\"Motifs show normal patterns, deviations indicate anomalies\",\n",
        "    status=TaskStatus.COMPLETE,\n",
        "    implementation_file=\"research/evaluation/probes/probes_baseline.ipynb\",\n",
        "    results_file=\"research/results/probe_metrics.json\",\n",
        "    notes=\"Implemented as binary classification probe\"\n",
        "))\n",
        "\n",
        "# Multi-file Activity Detection: Detect when activity spans multiple files\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"multi_file_detection\",\n",
        "    name=\"Multi-file Activity Detection\",\n",
        "    description=\"Detect when a coding task involves changes across multiple files\",\n",
        "    category=TaskCategory.CLASSIFICATION,\n",
        "    metrics=[\"accuracy\", \"f1_score\", \"file_count_accuracy\"],\n",
        "    expected_best_rungs=[\"files\", \"dependencies\", \"functions\"],\n",
        "    rationale=\"File and dependency graphs directly show multi-file relationships\",\n",
        "    status=TaskStatus.PARTIAL,\n",
        "    implementation_file=\"research/evaluation/probes/probes_baseline.ipynb\",\n",
        "    notes=\"Can be derived from existing probes\"\n",
        "))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Category 4: Search Tasks\n",
        "\n",
        "Tasks that involve searching for specific patterns, workflows, or code.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Event Retrieval: Search for specific events by natural language query\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"event_retrieval\",\n",
        "    name=\"Event Retrieval\",\n",
        "    description=\"Retrieve relevant events from history using natural language queries\",\n",
        "    category=TaskCategory.SEARCH,\n",
        "    metrics=[\"precision@k\", \"recall@k\", \"NDCG@k\", \"MRR\", \"overlap_analysis\"],\n",
        "    expected_best_rungs=[\"semantic_edits\", \"functions\", \"motifs\", \"tokens\"],\n",
        "    rationale=\"Different query types need different rungs - semantic for intent, tokens for exact matches\",\n",
        "    status=TaskStatus.NOT_STARTED,\n",
        "    implementation_file=\"research/evaluation/search/event_retrieval_evaluation.ipynb\",\n",
        "    notes=\"Notebook exists but not yet executed\"\n",
        "))\n",
        "\n",
        "# Procedural Search: Search for workflow patterns and sequences\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"procedural_search\",\n",
        "    name=\"Procedural Search\",\n",
        "    description=\"Search for workflow patterns, temporal sequences, and procedural knowledge\",\n",
        "    category=TaskCategory.SEARCH,\n",
        "    metrics=[\"precision@k\", \"recall@k\", \"NDCG@k\", \"pattern_distinctness\", \"workflow_coherence\"],\n",
        "    expected_best_rungs=[\"motifs\", \"semantic_edits\", \"functions\"],\n",
        "    rationale=\"Motifs capture workflow patterns, semantic edits show step-by-step processes\",\n",
        "    status=TaskStatus.COMPLETE,\n",
        "    implementation_file=\"research/evaluation/search/procedural_search_evaluation.ipynb\",\n",
        "    results_file=\"research/results/search_evaluation_results.json\",\n",
        "    notes=\"Evaluates baseline, intent-only, and intent+representation search\"\n",
        "))\n",
        "\n",
        "# Code Pattern Search: Search for specific code patterns or structures\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"code_pattern_search\",\n",
        "    name=\"Code Pattern Search\",\n",
        "    description=\"Search for specific code patterns, structures, or implementations\",\n",
        "    category=TaskCategory.SEARCH,\n",
        "    metrics=[\"precision@k\", \"recall@k\", \"pattern_match_accuracy\"],\n",
        "    expected_best_rungs=[\"tokens\", \"semantic_edits\", \"functions\"],\n",
        "    rationale=\"Tokens for exact patterns, semantic edits for structural patterns, functions for API patterns\",\n",
        "    status=TaskStatus.PARTIAL,\n",
        "    notes=\"Can be evaluated using event_retrieval with code-focused queries\"\n",
        "))\n",
        "\n",
        "# Similar Session Search: Find similar past sessions/workflows\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"similar_session_search\",\n",
        "    name=\"Similar Session Search\",\n",
        "    description=\"Find past sessions with similar workflows or patterns\",\n",
        "    category=TaskCategory.SEARCH,\n",
        "    metrics=[\"precision@k\", \"recall@k\", \"session_similarity_score\"],\n",
        "    expected_best_rungs=[\"motifs\", \"semantic_edits\", \"functions\"],\n",
        "    rationale=\"Motifs capture high-level workflow similarity\",\n",
        "    status=TaskStatus.PARTIAL,\n",
        "    notes=\"Can use motif clustering and similarity metrics\"\n",
        "))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Category 5: Segmentation Tasks\n",
        "\n",
        "Tasks that involve dividing activity into meaningful segments or sessions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Temporal Segmentation: Segment activity into task-based chunks\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"temporal_segmentation\",\n",
        "    name=\"Temporal Segmentation\",\n",
        "    description=\"Segment developer activity into meaningful task-based segments\",\n",
        "    category=TaskCategory.SEGMENTATION,\n",
        "    metrics=[\"completeness\", \"homogeneity\", \"boundary_quality\", \"semantic_coherence\", \"f1_score\"],\n",
        "    expected_best_rungs=[\"motifs\", \"semantic_edits\", \"functions\"],\n",
        "    rationale=\"Motifs show natural workflow boundaries, semantic edits show task transitions\",\n",
        "    status=TaskStatus.COMPLETE,\n",
        "    implementation_file=\"research/evaluation/segmentation/embedding_ground_truth_evaluation.ipynb\",\n",
        "    results_file=\"research/results/temporal_segmentation_inactivity_results.json\",\n",
        "    notes=\"Evaluates inactivity-based segmentation with embedding ground truth\"\n",
        "))\n",
        "\n",
        "# Intent-based Segmentation: Segment by developer intent\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"intent_segmentation\",\n",
        "    name=\"Intent-based Segmentation\",\n",
        "    description=\"Segment activity by developer intent (each segment = one intent)\",\n",
        "    category=TaskCategory.SEGMENTATION,\n",
        "    metrics=[\"intent_purity\", \"segment_coherence\", \"boundary_accuracy\"],\n",
        "    expected_best_rungs=[\"motifs\", \"semantic_edits\"],\n",
        "    rationale=\"Motifs capture intent patterns, semantic edits show intent transitions\",\n",
        "    status=TaskStatus.PARTIAL,\n",
        "    notes=\"Can be derived from intent classification + temporal segmentation\"\n",
        "))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Category 6: Analysis Tasks\n",
        "\n",
        "Tasks that involve analyzing code, patterns, or developer behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Expressiveness-Privacy Analysis: Measure trade-offs\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"expressiveness_privacy\",\n",
        "    name=\"Expressiveness-Privacy Trade-off\",\n",
        "    description=\"Measure expressiveness (within-trace similarity) vs privacy (cross-trace similarity)\",\n",
        "    category=TaskCategory.ANALYSIS,\n",
        "    metrics=[\"drift\", \"epsilon_equivalent\", \"k_anonymity\", \"within_similarity\", \"cross_similarity\"],\n",
        "    expected_best_rungs=[\"all\"],\n",
        "    rationale=\"Requires comparison across all rungs to understand trade-offs\",\n",
        "    status=TaskStatus.COMPLETE,\n",
        "    implementation_file=\"research/analysis/expressiveness/LLM_reconstruction_test.ipynb\",\n",
        "    results_file=\"research/results/expressiveness_privacy_tradeoff.png\",\n",
        "    notes=\"Core privacy-utility analysis\"\n",
        "))\n",
        "\n",
        "# Context Usage Analysis: Analyze how context is used\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"context_usage_analysis\",\n",
        "    name=\"Context Usage Analysis\",\n",
        "    description=\"Analyze how developers use context (files, snippets, dependencies) in their workflow\",\n",
        "    category=TaskCategory.ANALYSIS,\n",
        "    metrics=[\"context_coverage\", \"context_efficiency\", \"file_action_distribution\"],\n",
        "    expected_best_rungs=[\"files\", \"dependencies\", \"context_events\"],\n",
        "    rationale=\"File and dependency graphs show context relationships\",\n",
        "    status=TaskStatus.COMPLETE,\n",
        "    implementation_file=\"research/analysis/context/event_context_extraction.ipynb\",\n",
        "    results_file=\"research/results/event_context_table.csv\",\n",
        "    notes=\"Analyzes context extraction and usage patterns\"\n",
        "))\n",
        "\n",
        "# Workflow Pattern Analysis: Analyze common workflow patterns\n",
        "tasks.append(DeveloperTask(\n",
        "    id=\"workflow_pattern_analysis\",\n",
        "    name=\"Workflow Pattern Analysis\",\n",
        "    description=\"Identify and analyze common workflow patterns in developer activity\",\n",
        "    category=TaskCategory.ANALYSIS,\n",
        "    metrics=[\"pattern_frequency\", \"pattern_diversity\", \"pattern_clustering\"],\n",
        "    expected_best_rungs=[\"motifs\", \"semantic_edits\"],\n",
        "    rationale=\"Motifs are designed to capture workflow patterns\",\n",
        "    status=TaskStatus.PARTIAL,\n",
        "    notes=\"Can use motif mining and clustering results\"\n",
        "))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Task Summary Table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "DEVELOPER TASK SUITE SUMMARY\n",
            "================================================================================\n",
            "\n",
            "Total Tasks: 17\n",
            "\n",
            "By Status:\n",
            "status\n",
            "complete       10\n",
            "partial         6\n",
            "not_started     1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "By Category:\n",
            "category\n",
            "classification    4\n",
            "search            4\n",
            "analysis          3\n",
            "retrieval         2\n",
            "prediction        2\n",
            "segmentation      2\n",
            "Name: count, dtype: int64\n",
            "\n",
            "================================================================================\n",
            "DETAILED TASK LIST\n",
            "================================================================================\n",
            "                       id                             name       category      status                         expected_best_rungs                                                      implementation_file\n",
            "        context_retrieval                Context Retrieval      retrieval    complete          [semantic_edits, functions, files]                    research/evaluation/retrieval/context_retrieval.ipynb\n",
            "   file_context_retrieval     File-level Context Retrieval      retrieval    complete            [files, dependencies, functions]                    research/evaluation/retrieval/context_retrieval.ipynb\n",
            "    next_event_prediction            Next Event Prediction     prediction    complete         [semantic_edits, functions, motifs]                         research/evaluation/probes/probes_baseline.ipynb\n",
            "     next_file_prediction             Next File Prediction     prediction     partial               [files, dependencies, motifs]                         research/evaluation/probes/probes_baseline.ipynb\n",
            "  activity_classification          Activity Classification classification    complete         [semantic_edits, functions, motifs]                         research/evaluation/probes/probes_baseline.ipynb\n",
            "    intent_classification            Intent Classification classification    complete         [motifs, semantic_edits, functions]                         research/evaluation/probes/probes_baseline.ipynb\n",
            "        anomaly_detection                Anomaly Detection classification    complete         [motifs, semantic_edits, functions]                         research/evaluation/probes/probes_baseline.ipynb\n",
            "     multi_file_detection    Multi-file Activity Detection classification     partial            [files, dependencies, functions]                         research/evaluation/probes/probes_baseline.ipynb\n",
            "          event_retrieval                  Event Retrieval         search not_started [semantic_edits, functions, motifs, tokens]              research/evaluation/search/event_retrieval_evaluation.ipynb\n",
            "        procedural_search                Procedural Search         search    complete         [motifs, semantic_edits, functions]            research/evaluation/search/procedural_search_evaluation.ipynb\n",
            "      code_pattern_search              Code Pattern Search         search     partial         [tokens, semantic_edits, functions]                                                                     None\n",
            "   similar_session_search           Similar Session Search         search     partial         [motifs, semantic_edits, functions]                                                                     None\n",
            "    temporal_segmentation            Temporal Segmentation   segmentation    complete         [motifs, semantic_edits, functions] research/evaluation/segmentation/embedding_ground_truth_evaluation.ipynb\n",
            "      intent_segmentation        Intent-based Segmentation   segmentation     partial                    [motifs, semantic_edits]                                                                     None\n",
            "   expressiveness_privacy Expressiveness-Privacy Trade-off       analysis    complete                                       [all]           research/analysis/expressiveness/LLM_reconstruction_test.ipynb\n",
            "   context_usage_analysis           Context Usage Analysis       analysis    complete       [files, dependencies, context_events]                 research/analysis/context/event_context_extraction.ipynb\n",
            "workflow_pattern_analysis        Workflow Pattern Analysis       analysis     partial                    [motifs, semantic_edits]                                                                     None\n"
          ]
        }
      ],
      "source": [
        "# Create summary DataFrame\n",
        "df = pd.DataFrame([task.to_dict() for task in tasks])\n",
        "\n",
        "# Display summary\n",
        "print(\"=\" * 80)\n",
        "print(\"DEVELOPER TASK SUITE SUMMARY\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"\\nTotal Tasks: {len(tasks)}\")\n",
        "print(f\"\\nBy Status:\")\n",
        "print(df['status'].value_counts())\n",
        "print(f\"\\nBy Category:\")\n",
        "print(df['category'].value_counts())\n",
        "\n",
        "# Display detailed table\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"DETAILED TASK LIST\")\n",
        "print(\"=\" * 80)\n",
        "display_cols = ['id', 'name', 'category', 'status', 'expected_best_rungs', 'implementation_file']\n",
        "print(df[display_cols].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Rung Selection Guide\n",
        "\n",
        "Based on task characteristics, here's a guide for selecting the best rung:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RUNG SELECTION GUIDE\n",
            "================================================================================\n",
            "\n",
            "TOKENS\n",
            "  Best for: Exact code matching, Precise text search, Low-level pattern detection\n",
            "  Trade-off: Lowest privacy, highest storage\n",
            "\n",
            "SEMANTIC_EDITS\n",
            "  Best for: Intent-based retrieval, Pattern matching, Next event prediction\n",
            "  Trade-off: Good balance of expressiveness and privacy\n",
            "\n",
            "FUNCTIONS\n",
            "  Best for: API-level patterns, Structure-based search, Multi-file detection\n",
            "  Trade-off: Abstracts implementation, good for structure\n",
            "\n",
            "FILES\n",
            "  Best for: File-level context, Multi-file tasks, Dependency analysis\n",
            "  Trade-off: High abstraction, good privacy\n",
            "\n",
            "DEPENDENCIES\n",
            "  Best for: Structural relationships, Import analysis, Module-level tasks\n",
            "  Trade-off: Pure structure, no content\n",
            "\n",
            "MOTIFS\n",
            "  Best for: Workflow patterns, Intent classification, High-level search\n",
            "  Trade-off: Highest privacy, workflow-level only\n"
          ]
        }
      ],
      "source": [
        "# Rung selection guide\n",
        "rung_guide = {\n",
        "    \"tokens\": {\n",
        "        \"best_for\": [\"Exact code matching\", \"Precise text search\", \"Low-level pattern detection\"],\n",
        "        \"trade_off\": \"Lowest privacy, highest storage\"\n",
        "    },\n",
        "    \"semantic_edits\": {\n",
        "        \"best_for\": [\"Intent-based retrieval\", \"Pattern matching\", \"Next event prediction\"],\n",
        "        \"trade_off\": \"Good balance of expressiveness and privacy\"\n",
        "    },\n",
        "    \"functions\": {\n",
        "        \"best_for\": [\"API-level patterns\", \"Structure-based search\", \"Multi-file detection\"],\n",
        "        \"trade_off\": \"Abstracts implementation, good for structure\"\n",
        "    },\n",
        "    \"files\": {\n",
        "        \"best_for\": [\"File-level context\", \"Multi-file tasks\", \"Dependency analysis\"],\n",
        "        \"trade_off\": \"High abstraction, good privacy\"\n",
        "    },\n",
        "    \"dependencies\": {\n",
        "        \"best_for\": [\"Structural relationships\", \"Import analysis\", \"Module-level tasks\"],\n",
        "        \"trade_off\": \"Pure structure, no content\"\n",
        "    },\n",
        "    \"motifs\": {\n",
        "        \"best_for\": [\"Workflow patterns\", \"Intent classification\", \"High-level search\"],\n",
        "        \"trade_off\": \"Highest privacy, workflow-level only\"\n",
        "    }\n",
        "}\n",
        "\n",
        "print(\"RUNG SELECTION GUIDE\")\n",
        "print(\"=\" * 80)\n",
        "for rung, info in rung_guide.items():\n",
        "    print(f\"\\n{rung.upper()}\")\n",
        "    print(f\"  Best for: {', '.join(info['best_for'])}\")\n",
        "    print(f\"  Trade-off: {info['trade_off']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Implementation Status\n",
        "\n",
        "### ✅ Complete Tasks (9)\n",
        "- Context Retrieval\n",
        "- File-level Context Retrieval  \n",
        "- Next Event Prediction\n",
        "- Activity Classification\n",
        "- Intent Classification\n",
        "- Anomaly Detection\n",
        "- Procedural Search\n",
        "- Temporal Segmentation\n",
        "- Expressiveness-Privacy Analysis\n",
        "- Context Usage Analysis\n",
        "\n",
        "### ⚠️ Partial Tasks (5)\n",
        "- Next File Prediction\n",
        "- Multi-file Activity Detection\n",
        "- Code Pattern Search\n",
        "- Similar Session Search\n",
        "- Intent-based Segmentation\n",
        "- Workflow Pattern Analysis\n",
        "\n",
        "### ❌ Not Started (1)\n",
        "- Event Retrieval\n",
        "\n",
        "## Next Steps\n",
        "\n",
        "1. **Complete Event Retrieval**: Implement and run `event_retrieval_evaluation.ipynb`\n",
        "2. **Expand Partial Tasks**: Add dedicated evaluations for partial tasks\n",
        "3. **Advanced Probes**: Run `advanced_probes_comparison.ipynb` for ML model comparisons\n",
        "4. **Cross-task Analysis**: Compare rung performance across all tasks\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Task suite exported to research/results/developer_task_suite.json\n",
            "   Total tasks: 17\n",
            "   Complete: 10\n",
            "   Partial: 6\n",
            "   Not started: 1\n"
          ]
        }
      ],
      "source": [
        "# Export task suite to JSON for reference\n",
        "output_file = Path(\"research/results/developer_task_suite.json\")\n",
        "output_file.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump([task.to_dict() for task in tasks], f, indent=2)\n",
        "\n",
        "print(f\"✅ Task suite exported to {output_file}\")\n",
        "print(f\"   Total tasks: {len(tasks)}\")\n",
        "print(f\"   Complete: {sum(1 for t in tasks if t.status == TaskStatus.COMPLETE)}\")\n",
        "print(f\"   Partial: {sum(1 for t in tasks if t.status == TaskStatus.PARTIAL)}\")\n",
        "print(f\"   Not started: {sum(1 for t in tasks if t.status == TaskStatus.NOT_STARTED)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
